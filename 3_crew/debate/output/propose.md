There needs to be strict laws to regulate LLMs because, without proper oversight, these powerful tools can lead to significant societal harms. First and foremost, LLMs can perpetuate and amplify biases present in the data they are trained on, resulting in discriminatory outputs that can affect marginalized groups disproportionately. This can manifest in serious consequences, from biased hiring practices to unfair criminal justice outcomes. 

Moreover, the potential for misinformation and manipulation is alarming. LLMs can generate convincingly realistic but false information at an unprecedented scale, muddying the waters of public discourse and eroding trust in verified news. This can undermine democratic processes and create divisions among the population.

Additionally, without regulation, there is a risk of exploitation for malicious purposes. The ability to create deepfakes or other misleading content can be weaponized, impacting individuals' privacy and safety.

Finally, robust regulations would ensure accountability among developers and users, promoting responsible innovation while safeguarding public interests. Strict laws would not only protect individuals from harm but also establish clear ethical and operational standards that could foster public trust in LLM technologies.

In conclusion, strict laws regulating LLMs are essential to prevent bias, combat misinformation, protect safety, and ensure accountability, thus enabling the safe and beneficial development of this transformative technology.